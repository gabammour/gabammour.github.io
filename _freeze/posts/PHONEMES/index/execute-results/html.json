{
  "hash": "1b63311b4545ecad6baf4f6a84bda8ed",
  "result": {
    "markdown": "---\n    title: \"Une analyse du lien entre phon√®mes et fr√©quences sonores\"\n    author: \"Gabriel Ammour, [Th√©o Bouedo](https://lovely-dolphin-e68198.netlify.app/my_work.html)\"\n    date: \"2023-04-06\"\n    categories: [School projects]\n    description: \"üîâ\"\n    format: \n      html: \n        toc: true\n        code-fold: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n# Introduction\n\nLes donn√©es pr√©sent√©es proviennent de l'ouvrage de r√©f√©rence intitul√© \"Elements of Statistical Learning\" de Hastie, Tibshirani et Friedman (2009). Elles concernent l'analyse des phon√®mes et ont √©t√© extraites de la base de donn√©es TIMIT, qui est une ressource largement utilis√©e dans la recherche en reconnaissance vocale. Le phon√®me est l'unit√© sonore de base de la langue parl√©e. C'est la plus petite unit√© distinctive de son qui permet de distinguer un mot d'un autre dans une langue donn√©e. Le but du projet est de discriminer cinq phon√®mes, transcrits comme suit : *sh* pour \"she\", *dcl* pour \"dark\", *iy* pour la voyelle dans \"she\", *aa* pour la voyelle dans \"dark\", et *ao* pour la premi√®re voyelle dans \"water\".\n\nLe corpus de donn√©es se compose de 50 discours enregistr√©s, √† partir desquels ont √©t√© s√©lectionn√©es 4509 trames vocales d'une dur√©e de 32 ms, comportant environ deux exemples de chaque phon√®me pour chaque locuteur. Le tableau de donn√©es obtenu contient 4509 lignes et 256 colonnes, intitul√©es \"x.1\" - \"x.256\", qui correspondent aux valeurs du log-p√©riodogramme mesur√©es sur les diff√©rentes trames. Les deux derni√®res colonnes indiquent le phon√®me prononc√© et le locuteur. Chaque trame est identifi√©e comme appartenant √† l'ensemble d'apprentissage (train) ou de test (test), en fonction de la colonne locuteur. Pour faire plus simple, nous pouvons dire que chaque ligne repr√©sente une trame vocale et que l'ensemble des colonnes repr√©sentent le spectre sonore de chaque trame. Ainsi, nous retrouvons 256 colonnes car le periodogramme s'√©tends sur une plage de 256 Hz. Par ailleurs, nous pouvons pr√©ciser que sur les 4509 observations, 25.8% d'entre elles sont *iy*, 15.4% sont *aa*, 19.3% sont *sh*, 22.7% sont *ao* et 16.8 sont *dcl*.\n\n# Statistiques descriptives\n\n\n\n\n\n√âtant donn√© que notre base de donn√©es comporte un nombre significatif de lignes et de colonnes, il n'est pas judicieux d'effectuer une analyse descriptive d√©taill√©e pour chacune de nos variables. N√©anmoins, nous pouvons opter pour la projection des cinq phon√®mes distincts afin d'obtenir une premi√®re impression des similarit√©s potentielles entre chaque phon√®me. En examinant les valeurs moyennes projet√©es de chaque phon√®me sur le p√©riodogramme, nous pouvons observer certaines tendances dans les comportements acoustiques. Il est notable que l'intensit√© moyenne de chaque phon√®me est plus √©lev√©e dans les basses fr√©quences, situ√©es au d√©but du spectre sonore. Concernant les raisons de cette observation, il est possible d'√©mettre l'hypoth√®se que cela soit d√ª au fait que les phon√®mes √©tudi√©s sont des voyelles. Par ailleurs, le phon√®me *dcl* semble se distinguer des autres, se caract√©risant par des niveaux d'intensit√© plus faibles d√®s le d√©but du spectre, comparativement aux autres phon√®mes. Ce dernier est notamment oppos√© au phon√®me *sh* en termes d'intensit√© sonore.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(mean_data, aes(x = variable, y = value, color = phoneme, group = phoneme)) +\n  geom_line() +\n  scale_x_discrete(breaks = seq(1, nrow(phoneme_stats[[1]]), by = 50), labels = seq(1, nrow(phoneme_stats[[1]]), by = 50)) +\n  theme_bw() +\n  labs(x = \"Variable (Periodogram)\",\n       y = \"Valeur moyenne\") +\n  theme(legend.position = \"bottom\",\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill = \"#FFFFF6\"))\n```\n\n::: {.cell-output-display}\n![Log-periodogramme moyen par valeur et par phon√®me](index_files/figure-html/fig-period-1.png){#fig-period fig-align='center' width=672}\n:::\n:::\n\n\nAvec la fonction `plot.PCA` de la biblioth√®que `FactoMineR`, nous sommes en mesure de repr√©senter chaque observation sur un plan bidimensionnel et de regrouper les phon√®mes par couleur. Dans ce contexte, la @fig-pca nous permet de confirmer que chaque phon√®me occupe effectivement la m√™me position dans le spectre sonore. Ce graphique nous permet √©galement de diff√©rencier clairement les phon√®mes les uns des autres. Par exemple, il est possible de constater que les sons *sh* et *dcl* sont situ√©s √† des extr√©mit√©s oppos√©es. Nous observons √©galement que les voyelles *aa*, *ao* et *sh* sont tr√®s proches les unes des autres, indiquant que ces trois phon√®mes pr√©sentent des similarit√©s en termes de fr√©quence sur le p√©riodogramme.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Projection graphique des individus](index_files/figure-html/fig-pca-1.png){#fig-pca fig-align='center' width=672}\n:::\n:::\n\n\n\n\n# Classification\n\nLa classification a pour objectif de diviser un ensemble de donn√©es en groupes distincts et homog√®nes. Ces groupes, souvent appel√©s clusters, se composent d'√©l√©ments pr√©sentant des caract√©ristiques similaires. Dans cette √©tude, nous utiliserons une classification hi√©rarchique pour partitionner notre base de donn√©es en divers ensembles. Cette classification reposera sur la m√©thode de Ward, l'une des m√©thodes les plus populaires, permettant notamment de minimiser l'inertie intra-classe et de maximiser l'inertie inter-classe. Cette approche nous permettra, *in fine*, d'obtenir des sous-ensembles plus homog√®nes. Le diagramme √† barres et le dendrogramme de la figure @fig-classification r√©v√®lent trois partitions, c'est-√†-dire trois classes. En effet, nous pouvons observer trois sauts d'inerties, ou trois coudes, indiquant une s√©paration naturelle en trois groupes.\n\n\n\n\n\n\n::: {#fig-classification .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nggplot(barplot_df, aes(x = index, y = height)) +\n   labs(x = \"Index\",\n       y = \"Va\") +\n  geom_bar(stat = \"identity\", fill = \"royalblue\") +\n   theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill = \"#FFFFF6\")) +\n  theme_bw() \n\nggplot(color_branches(arbre, k = 3), labels = FALSE)\n```\n\n::: {.cell-output-display}\n![Barplot](index_files/figure-html/fig-classification-1.png){#fig-classification-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Dendrogramme](index_files/figure-html/fig-classification-2.png){#fig-classification-2 width=672}\n:::\n\nBarplot et Dendrogramme\n:::\n\n\nA priori, notre √©chantillon se divise en trois groupes distincts. Par cons√©quent, nous pouvons effectuer une coupe de l'arbre de classification hi√©rarchique afin d'obtenir trois clusters. Apr√®s le calcul des centres de gravit√©, nous appliquons la m√©thode des k-means en utilisant l'algorithme de MacQueen. Ces calculs nous permettent d'identifier trois clusters constitu√©s comme ci-dessous.\n\n| Phon√®mes | Clust. 1 | Clust. 2 | Clust. 3 |\n|----------|----------|----------|----------|\n| aa       | 1.0      | **24.6** | 0.2      |\n| ao       | 0.6      | **35.9** | 1.9      |\n| dcl      | 0.4      | 1.5      | **97.6** |\n| iy       | 9.5      | **37.6** | 0.4      |\n| sh       | **88.5** | 0.3      | 0        |\n\n: R√©partition des phon√®mes dans les diff√©rents clusters (en %) {#tbl-clust}\n\nLa @tbl-clust indique comment chaque phon√®me est r√©parti. Nous observons que le premier cluster est majoritairement compos√© du phon√®me *sh* avec 88,5% des observations. Le second, le plus important en termes d'effectif, est principalement constitu√© des phon√®mes *aa*, *ao* et *iy*. Enfin, le troisi√®me cluster se compose presque exclusivement du phon√®me *dcl* avec 97,6% des observations. Ainsi, le clustering effectu√© confirme les premi√®res observations faites dans la partie statistiques descriptives : nous identifions bien trois groupes distincts, dont trois phon√®mes partageant des caract√©ristiques tr√®s similaires entre eux et deux autres poss√©dant leurs propres sp√©cificit√©s. Pour v√©rifier si les associations entre les clusters et les phon√®mes sont significatives, nous pouvons utiliser le test du $\\chi2$. En effectuant le test √† l'aide de la commande `chisq.test` sur le logiciel R, nous obtenons une p-value inf√©rieure √† 0,05. Par cons√©quent, nous pouvons conclure qu'il existe une association significative entre les phon√®mes et les clusters. En ce qui concerne l'interpr√©tation des clusters, nous pouvons faire certaines hypoth√®ses. Par exemple, le premier cluster pourrait √™tre associ√© √† des phon√®mes \"chuchot√©s\" ou prononc√©s avec une certaine r√©serve. Le deuxi√®me cluster pourrait correspondre √† des phon√®mes \"vibrants\" ou \"nasalis√©s\", qui pr√©sentent des caract√©ristiques acoustiques similaires en termes de fr√©quence. Le troisi√®me cluster pourrait √™tre associ√© √† des phon√®mes prononc√©s avec une certaine emphase ou une accentuation particuli√®re.\n\n\n\n\n\n\n\n\n\n\n\n# Discrimination\n\nLe but de cette partie va √™tre de mener une analyse discriminante sur nos phon√®mes. Tr√®s simplement, l'analyse discriminante est une m√©thode statistique utilis√©e pour trouver les caract√©ristiques qui diff√©rencient le mieux des groupes d'observations. Ici, notre objectif va donc √™tre de trouver les fr√©quences acoustiques qui permettent de diff√©rencier au mieux les diff√©rents phon√®mes. Mieux diff√©rencier les phon√®mes peut nous permettre *in fine* d'am√©liorer nos connaissances dans le domaine de la reconnaissance vocale. Pour effectuer cette discrimination, nous utiliserons deux m√©thodes, l'analyse factorielle discriminante et la PLS DA.\n\n## Analyse Factorielle discriminante\n\nL'analyse factorielle discriminante (AFD) est une m√©thode statistique qui permet d'identifier les fr√©quences acoustiques discriminantes pour les diff√©rents phon√®mes. Pour mener √† bien cette technique, les donn√©es sont divis√©es en deux √©chantillons. Ensuite, le mod√®le est entra√Æn√© √† l'aide de la fonction `lda` du package `MASS`. Afin d'estimer la pr√©cision du mod√®le, il est possible de le tester sur l'√©chantillon test et d'obtenir une matrice de confusion (@tbl-AFD ). Cette matrice permet de visualiser la r√©partition des phon√®mes entre leurs classes initiales et les classes pr√©dites par le mod√®le. Les r√©sultats montrent que le mod√®le est assez pr√©cis, √† l'exception des phon√®mes *aa* et *ao* qui pr√©sentent un taux d'erreur d'environ 20%, tandis que tous les autres phon√®mes ont un taux d'erreur proche de 1%. Ces r√©sultats sont confirm√©s par la pr√©cision globale du mod√®le, qui s'√©l√®ve √† 93%.\n\n| Classe Pr√©dite | aa  | ao  | dcl | iy  | sh  |\n|----------------|-----|-----|-----|-----|-----|\n| **aa**         | 106 | 30  | 0   | 0   | 0   |\n| **ao**         | 33  | 186 | 0   | 0   | 0   |\n| **dcl**        | 0   | 0   | 182 | 2   | 0   |\n| **iy**         | 0   | 0   | 3   | 259 | 0   |\n| **sh**         | 0   | 0   | 1   | 0   | 200 |\n\n: Matrice de confusion de l'AFD {#tbl-AFD}\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n### Variables les plus discriminantes\n\nA pr√©sent, nous proc√©dons √† l'identification des phon√®mes les plus discriminants. En obtenant les scores d'importance des variables, nous observons que les dix phon√®mes les plus discriminants se situent presque tous autour de la fr√©quence x20 (@tbl-10). Nous pouvons ainsi affirmer que les fr√©quences basses, c'est-√†-dire celles du d√©but du spectre, sont les plus importantes pour distinguer les diff√©rents groupes de phon√®mes dans notre jeu de donn√©es. Nous pouvons √©mettre l'hypoth√®se que les caract√©ristiques acoustiques des phon√®mes peuvent varier en fonction de l'articulation et de la position dans la parole. Les fr√©quences basses pourraient ainsi refl√©ter des aspects importants de l'articulation, tels que la mani√®re dont les cordes vocales vibrent ou la mani√®re dont les cavit√©s buccales et nasales modifient les sons produits. Ces fr√©quences basses pourraient donc fournir des informations cruciales pour diff√©rencier les phon√®mes.\n\n| Variables | coef       | importance |\n|-----------|------------|------------|\n| x.17      | -0.1435770 | 0.0206144  |\n| x.18      | -0.1326711 | 0.0176016  |\n| x.19      | -0.1185520 | 0.0140546  |\n| x.20      | -0.1125399 | 0.0126652  |\n| x.12      | 0.1018741  | 0.0103783  |\n| x.9       | 0.0883249  | 0.0078013  |\n| x.16      | -0.0865254 | 0.0074866  |\n| x.35      | -0.0821173 | 0.0067433  |\n| x.10      | 0.0802089  | 0.0064335  |\n| x.11      | 0.0750107  | 0.0056266  |\n\n: Les 10 fr√©quences les plus discriminantes {#tbl-10}\n\nPour conclure avec cette m√©thode, nous avons tent√© d'utiliser la m√©thode LASSO (Least Absolute Shrinkage and Selection Operator) pour s√©lectionner les variables les plus pertinentes pour la classification. Malheureusement, nos r√©sultats ont indiqu√© que le processus de s√©lection de variables n'avait pas d'impact significatif sur la performance du mod√®le.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## PLS-DA\n\nLa deuxi√®me m√©thode d'analyse supervis√©e que nous avons utilis√©e pour cette √©tude est la PLS-DA. Cette analyse est int√©ressante et vient compl√©ter l'AFD, car elle nous permet de prendre en compte la corr√©lation qui peut exister entre les diff√©rentes caract√©ristiques acoustiques de nos phon√®mes. De plus, la PLS-DA permet de pr√©dire la classe d'un nouvel individu en fonction de ses caract√©ristiques acoustiques. Dans le cas de l'analyse des phon√®mes, cela peut √™tre utile pour identifier la classe d'un phon√®me inconnu √† partir de ses caract√©ristiques acoustiques. Pour r√©aliser notre PLS-DA, nous avons utilis√© uniquement le package `Mix0mics` de R. Comme pour l'AFD, nous avons commenc√© par d√©finir deux √©chantillons, un d'apprentissage et un d'entra√Ænement. Ensuite, nous avons utilis√© la fonction `plsda` avec l'√©chantillon d'apprentissage pour estimer un premier mod√®le. Notons que ce mod√®le est effectu√© sur cinq composantes pour les cinq phon√®mes. √Ä la suite de ce premier mod√®le, nous avons obtenu un graphique relativement similaire √† ce qui avait pu √™tre fait dans notre partie d'analyse de donn√©es. Cependant, en utilisant la validation crois√©e, nous avons d√©termin√© un nombre optimal de trois composantes. La @fig-plsda3 nous donne une repr√©sentation graphique de la PLS-DA effectu√©e. Nous pouvons observer que mise √† part les phon√®mes *aa* et *ao*, les trois autres phon√®mes arrivent bien √† se d√©tacher et √† se regrouper entre eux par rapport √† la premi√®re PLS-DA effectu√©e sur cinq composantes.\n\n\n\n\n::: {#fig-plsda3 .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# Visualisation des individus dans l'espace des trois premi√®res composantes principales\nplotIndiv(plsda_res5, group = Y_train, legend.title = \"Phon√®me\", ellipse = TRUE, legend = TRUE,\n          title = \"PLS-DA sur cinq composantes\")\nplotIndiv(plsda_res3, comp = c(1,3), group = Y_train, legend.title = \"Phon√®me\", ellipse = TRUE, legend = TRUE,\n          title =\" PLS-DA sur trois composantes\")\n```\n\n::: {.cell-output-display}\n![5 composantes](index_files/figure-html/fig-plsda3-1.png){#fig-plsda3-1 width=672}\n:::\n\n::: {.cell-output-display}\n![3 composantes](index_files/figure-html/fig-plsda3-2.png){#fig-plsda3-2 width=672}\n:::\n\nRepr√©sentations graphiques des PLS-DA\n:::\n\n\n### Mesures de performances\n\nAfin d'√©valuer la performance du mod√®le, nous avons proc√©d√© √† une pr√©diction sur l'√©chantillon test. La mesure utilis√©e pour cette pr√©diction est la distance de Mahalanobis, qui permet d'√©valuer la similarit√© entre deux observations en prenant en compte leur corr√©lation. Dans le cadre de notre √©tude, cette distance indique un taux de classification correcte de 0,7197, soit 71,97% d'observations correctement class√©es en fonction de leur groupe d'appartenance. Comme pour l'analyse factorielle discriminante, une matrice de confusion a √©t√© construite √† partir de l'√©chantillon test. Cette matrice r√©v√®le un taux d'erreur de 22%, ce qui indique une pr√©cision moindre du mod√®le. Ce taux d'erreur est d√ª √† la difficult√© pour le mod√®le √† distinguer les diff√©rences entre les deux phon√®mes les plus proches, √† savoir *aa* et *ao.*\n\n\n\n\n\n### Contribution aux composantes\n\nEnfin, pour compl√©ter l'analyse, nous avons d√©cid√© de projeter les fr√©quences acoustiques ayant le plus d'importances dans la formation de nos trois composantes (@fig-comp). Les fr√©quences acoustiques les plus discriminantes pour la composante 1 sont celles qui se trouvaient √† droite du spectre acoustique et qui correspondaient au phon√®me *sh.* Les fr√©quences les plus discriminantes pour les composantes 2 et 3 sont les fr√©quences les plus basses, correspondant respectivement aux phon√®mes *aa*, *ao* et *iy.* Cependant, aucune des variables correspondantes n'a contribu√© n√©gativement √† la composante 2, alors que le phon√®me *iy* a contribu√© positivement √† la composante 3. Ainsi, il semble que les fr√©quences basses soient importantes pour la discrimination des phon√®mes, en particulier pour les phon√®mes *aa*, *ao* et *iy.* En revanche, les fr√©quences les plus √©lev√©es du spectre acoustique semblent √™tre importantes pour la discrimination du phon√®me *sh.* Ces r√©sultats sont coh√©rents avec la litt√©rature sur la perception des phon√®mes, qui indique que les fr√©quences basses peuvent √™tre importantes pour la reconnaissance des phon√®mes, en particulier pour les voyelles.\n\n\n::: {#fig-comp .cell layout-ncol=\"3\"}\n\n```{.r .cell-code}\n# Visualisation des individus dans l'espace des trois premi√®res composantes principales\nplotLoadings(plsda_res3, comp = 1, method = 'median', contrib = \"max\", title = \"Composante 1\")\nplotLoadings(plsda_res3, comp = 2, method = 'median', contrib = \"max\", title = \"Composante 2\")\nplotLoadings(plsda_res3, comp = 3, method = 'median', contrib = \"max\", title = \"Composante 3\")\n```\n\n::: {.cell-output-display}\n![Composante 1](index_files/figure-html/fig-comp-1.png){#fig-comp-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Composante 2](index_files/figure-html/fig-comp-2.png){#fig-comp-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Composante 3](index_files/figure-html/fig-comp-3.png){#fig-comp-3 width=672}\n:::\n\nContributions des individus aux trois composantes\n:::\n\n\n# Conclusion\n\nEn utilisant des m√©thodes de statistiques et d'analyse de donn√©es, l'objectif de cette √©tude √©tait de mieux comprendre les liens entre les phon√®mes et les fr√©quences sonores. Dans la premi√®re partie, une analyse de statistique descriptive a √©t√© r√©alis√©e pour distinguer trois groupes de phon√®mes. √Ä l'aide du graphique des individus et du periodogramme, des similitudes ont √©t√© observ√©es entre les phon√®mes *aa*, *ao* et *iy*, ainsi qu'une opposition entre les phon√®mes *dcl* et *sh*. Ces observations ont √©t√© confirm√©es par notre classification qui a permis de d√©gager trois clusters distincts. En accord avec l'analyse pr√©liminaire, le cluster 1 √©tait majoritairement compos√© du phon√®me *sh*, le cluster 2 √©tait majoritairement compos√© des phon√®mes *aa*, *ao* et *sh*, et enfin, le cluster 3 √©tait compos√© en grande partie du phon√®me *dcl*.\n\nEnsuite, une analyse discriminante a √©t√© r√©alis√©e pour identifier les fr√©quences sonores qui permettaient de discriminer au mieux les diff√©rents phon√®mes. L'analyse discriminante factorielle a montr√© que ce sont les fr√©quences les plus basses qui semblaient discriminer au mieux les diff√©rents phon√®mes. Cette observation est en accord avec l'analyse du periodogramme qui montrait que le niveau des fr√©quences √©tait en moyenne plus √©lev√© au d√©but du spectre sonore. Bien que ces observations ne permettent pas de tirer des conclusions certaines, il est possible que ces r√©sultats soient dus au fait que tous les phon√®mes √©tudi√©s sont des voyelles.\n\nEnfin, pour compl√©ter notre analyse discriminante, une analyse PLS-DA a √©t√© effectu√©e. Les r√©sultats de cette PLS-DA ont confirm√© que les fr√©quences les plus basses pouvaient √™tre un facteur discriminant pour l'identification des phon√®mes, en particulier pour les phon√®mes les plus similaires, tels que *aa*, *ao* et *iy*. Cependant, les performances de la PLS-DA se sont av√©r√©es moins robustes que celles de l'AFD. Dans le cadre de cet √©chantillon, il est donc possible que l'AFD soit suffisante pour obtenir une bonne discrimination.\n\n# Discussion\n\nSi dans cette √©tude, nous avons identifi√© les fr√©quences basses comme √©tant un √©l√©ment cl√© pour discriminer les phon√®mes, il est utile de pr√©ciser que ces caract√©ristiques acoustiques ne sont pas les seules √† pouvoir les discriminer. D'autres caract√©ristiques telles que la dur√©e du phon√®me ou les transitions de fr√©quences entre les phon√®mes peuvent √©galement jouer un r√¥le important dans la reconnaissance vocale. Dans cette √©tude, nous avons d√ª faire avec les donn√©es qui nous √©taient fournis, ainsi les r√©sultats pourraient s'av√©rer diff√©rents avec un autre √©chantillon de phon√®mes. De plus, il faut tenir compte du fait que ces r√©sultats ne sont pas forc√©ment g√©n√©ralisable √† d'autres langues et populations.\n\n[PDF](var_latentes.pdf)\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}