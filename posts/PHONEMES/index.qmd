---
    title: "Une analyse du lien entre phon√®mes et fr√©quences sonores"
    author: "Gabriel Ammour, [Th√©o Bouedo](https://lovely-dolphin-e68198.netlify.app/my_work.html)"
    date: "2023-04-06"
    categories: [School projects]
    description: "üîâ"
    format: 
      html: 
        toc: true
        code-fold: true
---

```{r,  echo=FALSE, eval=TRUE, message=FALSE}
{
  library(devtools)
  library(dplyr)
  library(tidyverse)
  library(ggplot2)
  library(parallel)
  library(FactoMineR)
  library(factoextra)
  library(caret)
  library(klaR)
  library(NbClust)
  library(dendextend)
  library(readr)
  library(dplyr)
  library(knitr)
  library(datawizard)
  library(MASS)
  library(pls)
  library(plsRglm)
  library(mdatools)
  library(FactoMineR)
  library(mixOmics)
  library(rgeoda)
  
}
```

```{r, echo=FALSE, eval=TRUE, include=FALSE}
# Charger les donn√©es
  df <- read.csv2("base.csv", sep = ";")

# D√©placer la derni√®re colonne en premi√®re position :
df <- df %>%
  relocate(names(df)[ncol(df)], .before = names(df)[1])

# D√©placer la colonne "g" en premi√®re position :
df <- df %>%
  relocate(g, .before = names(df)[1])

# Convertir la colonne "g" en facteur
df$g <- as.factor(df$g)

# Convertir toutes les colonnes commen√ßant par "x." en num√©rique
df <- df %>% mutate(across(starts_with("x."), as.numeric)) 

# Supprimer la colonne "row.names"
if ("row.names" %in% names(df)) {
  df <- df[, -which(names(df) == "row.names")]
} 

data_codebook(df, select = starts_with("g"))
```

```{r, echo=FALSE, eval=TRUE}
# Cr√©ation de train et test
df_train <- df[grepl("train", df$speaker), ]
df_train  = df_train[,-c(2)]
df_test <- df[grepl("test", df$speaker), ]
df_test  = df_test[,-c(2)]
df  = df[,-c(2)]
```

# Introduction

Les donn√©es pr√©sent√©es proviennent de l'ouvrage de r√©f√©rence intitul√© "Elements of Statistical Learning" de Hastie, Tibshirani et Friedman (2009). Elles concernent l'analyse des phon√®mes et ont √©t√© extraites de la base de donn√©es TIMIT, qui est une ressource largement utilis√©e dans la recherche en reconnaissance vocale. Le phon√®me est l'unit√© sonore de base de la langue parl√©e. C'est la plus petite unit√© distinctive de son qui permet de distinguer un mot d'un autre dans une langue donn√©e. Le but du projet est de discriminer cinq phon√®mes, transcrits comme suit : *sh* pour "she", *dcl* pour "dark", *iy* pour la voyelle dans "she", *aa* pour la voyelle dans "dark", et *ao* pour la premi√®re voyelle dans "water".

Le corpus de donn√©es se compose de 50 discours enregistr√©s, √† partir desquels ont √©t√© s√©lectionn√©es 4509 trames vocales d'une dur√©e de 32 ms, comportant environ deux exemples de chaque phon√®me pour chaque locuteur. Le tableau de donn√©es obtenu contient 4509 lignes et 256 colonnes, intitul√©es "x.1" - "x.256", qui correspondent aux valeurs du log-p√©riodogramme mesur√©es sur les diff√©rentes trames. Les deux derni√®res colonnes indiquent le phon√®me prononc√© et le locuteur. Chaque trame est identifi√©e comme appartenant √† l'ensemble d'apprentissage (train) ou de test (test), en fonction de la colonne locuteur. Pour faire plus simple, nous pouvons dire que chaque ligne repr√©sente une trame vocale et que l'ensemble des colonnes repr√©sentent le spectre sonore de chaque trame. Ainsi, nous retrouvons 256 colonnes car le periodogramme s'√©tends sur une plage de 256 Hz. Par ailleurs, nous pouvons pr√©ciser que sur les 4509 observations, 25.8% d'entre elles sont *iy*, 15.4% sont *aa*, 19.3% sont *sh*, 22.7% sont *ao* et 16.8 sont *dcl*.

# Statistiques descriptives

```{r, echo=FALSE, eval=TRUE, include=FALSE}
phoneme_groups <- split(df, df$g)

# Fonction pour calculer les statistiques descriptives
descriptive_stats <- function(data) {
  
  numeric_data <- data[, grepl("^x\\.", colnames(data))]
  
  summary_stats <- data.frame(
    mean = colMeans(numeric_data),
    median = apply(numeric_data, 2, median),
    sd = apply(numeric_data, 2, sd),
    min = apply(numeric_data, 2, min),
    max = apply(numeric_data, 2, max)
  )
  return(summary_stats)
}

# Appliquer la fonction aux groupes de phon√®mes

phoneme_stats <- lapply(phoneme_groups, descriptive_stats)



#numeric_data <- df[, grepl("^x\\.", colnames(df))] 
# Ajoutez une colonne pour le phon√®me
#numeric_data$g <- df$g

# Convertissez les donn√©es en format long
#long_data <- reshape2::melt(numeric_data, id.vars = "g", variable.name = "variable", value.name = "value")
# Convertir la liste en data.frame
phoneme_stats_df <- do.call(rbind, phoneme_stats)

# Ajouter une colonne avec les noms des phon√®mes
phoneme_stats_df$phoneme <- rep(names(phoneme_groups), each = nrow(phoneme_stats[[1]]))

# Ajouter une colonne avec les num√©ros de variable (p√©riodogramme)
phoneme_stats_df$variable <- factor(rep(1:nrow(phoneme_stats[[1]]), length(unique(phoneme_stats_df$phoneme))), levels = 1:nrow(phoneme_stats[[1]]))

# Convertir les donn√©es en format long
long_phoneme_stats_df <- reshape2::melt(phoneme_stats_df, id.vars = c("phoneme", "variable"), variable.name = "statistic", value.name = "value")

# Ajouter une colonne avec les num√©ros de variable (p√©riodogramme)
mean_data <- long_phoneme_stats_df[long_phoneme_stats_df$statistic == "mean", ]


# Extraire les moyennes de long_phoneme_stats_df
mean_data <- long_phoneme_stats_df[long_phoneme_stats_df$statistic == "mean",]

# Cr√©er une colonne "variable" avec les num√©ros de variable (p√©riodogramme) pour chaque phon√®me
mean_data$variable <- factor(rep(1:nrow(phoneme_stats[[1]]), length(unique(mean_data$phoneme))), levels = 1:nrow(phoneme_stats[[1]]))
```

√âtant donn√© que notre base de donn√©es comporte un nombre significatif de lignes et de colonnes, il n'est pas judicieux d'effectuer une analyse descriptive d√©taill√©e pour chacune de nos variables. N√©anmoins, nous pouvons opter pour la projection des cinq phon√®mes distincts afin d'obtenir une premi√®re impression des similarit√©s potentielles entre chaque phon√®me. En examinant les valeurs moyennes projet√©es de chaque phon√®me sur le p√©riodogramme, nous pouvons observer certaines tendances dans les comportements acoustiques. Il est notable que l'intensit√© moyenne de chaque phon√®me est plus √©lev√©e dans les basses fr√©quences, situ√©es au d√©but du spectre sonore. Concernant les raisons de cette observation, il est possible d'√©mettre l'hypoth√®se que cela soit d√ª au fait que les phon√®mes √©tudi√©s sont des voyelles. Par ailleurs, le phon√®me *dcl* semble se distinguer des autres, se caract√©risant par des niveaux d'intensit√© plus faibles d√®s le d√©but du spectre, comparativement aux autres phon√®mes. Ce dernier est notamment oppos√© au phon√®me *sh* en termes d'intensit√© sonore.

```{r, echo=TRUE, eval=TRUE, fig.align="center"}
#| label: fig-period
#| fig-cap: "Log-periodogramme moyen par valeur et par phon√®me"
ggplot(mean_data, aes(x = variable, y = value, color = phoneme, group = phoneme)) +
  geom_line() +
  scale_x_discrete(breaks = seq(1, nrow(phoneme_stats[[1]]), by = 50), labels = seq(1, nrow(phoneme_stats[[1]]), by = 50)) +
  theme_bw() +
  labs(x = "Variable (Periodogram)",
       y = "Valeur moyenne") +
  theme(legend.position = "bottom",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "#FFFFF6"))

```

Avec la fonction `plot.PCA` de la biblioth√®que `FactoMineR`, nous sommes en mesure de repr√©senter chaque observation sur un plan bidimensionnel et de regrouper les phon√®mes par couleur. Dans ce contexte, la @fig-pca nous permet de confirmer que chaque phon√®me occupe effectivement la m√™me position dans le spectre sonore. Ce graphique nous permet √©galement de diff√©rencier clairement les phon√®mes les uns des autres. Par exemple, il est possible de constater que les sons *sh* et *dcl* sont situ√©s √† des extr√©mit√©s oppos√©es. Nous observons √©galement que les voyelles *aa*, *ao* et *sh* sont tr√®s proches les unes des autres, indiquant que ces trois phon√®mes pr√©sentent des similarit√©s en termes de fr√©quence sur le p√©riodogramme.

```{r,  echo=FALSE, eval=TRUE, include=FALSE}
res.pca <- PCA (df,scale.unit=TRUE,quali.sup=1,graph=FALSE)
res <- barplot(res.pca$eig[1:10],xlab="Dim.",ylab="Percentage of variance")
plot(res.pca,choix="var")
```

```{r, echo=FALSE, eval=TRUE, fig.align="center"}
#| label: fig-pca
#| fig-cap: "Projection graphique des individus"
FactoMineR::plot.PCA(res.pca,choix="ind",habillage=1, label="quali")
```

```{r, include=FALSE, echo=FALSE, eval=FALSE}
phoneme_counts <- table(df$g)
barplot(phoneme_counts, main = "Distribution des phon√®mes")
```

# Classification

La classification a pour objectif de diviser un ensemble de donn√©es en groupes distincts et homog√®nes. Ces groupes, souvent appel√©s clusters, se composent d'√©l√©ments pr√©sentant des caract√©ristiques similaires. Dans cette √©tude, nous utiliserons une classification hi√©rarchique pour partitionner notre base de donn√©es en divers ensembles. Cette classification reposera sur la m√©thode de Ward, l'une des m√©thodes les plus populaires, permettant notamment de minimiser l'inertie intra-classe et de maximiser l'inertie inter-classe. Cette approche nous permettra, *in fine*, d'obtenir des sous-ensembles plus homog√®nes. Le diagramme √† barres et le dendrogramme de la figure @fig-classification r√©v√®lent trois partitions, c'est-√†-dire trois classes. En effet, nous pouvons observer trois sauts d'inerties, ou trois coudes, indiquant une s√©paration naturelle en trois groupes.

```{r, echo=FALSE, eval=TRUE, include=FALSE}
data.cr <- scale(df_train[,-1],center=TRUE,scale=TRUE) # standardise les donn√©es en les centrant

data.dist <- dist(data.cr) # Calcule la matrice des distances euclidiennes entre les observations standardis√©es.
data.hca <- hclust(data.dist,method="ward.D2") # Classification hi√©rarchique agglom√©rative en utilisant la m√©thode de Ward
par(mfrow=c(1,2))

height_data <- rev(data.hca$height)[1:30]
barplot_df <- data.frame(index = 1:length(height_data), height = height_data)
```

```{r,  echo=FALSE, eval=TRUE, include=FALSE}

arbre <- hclust(data.dist,method="ward.D2")
plot(arbre)


inertie <- sort(arbre$height, decreasing = TRUE)
plot(inertie[1:20], type = "s", xlab = "Nombre de classes", ylab = "Inertie")
```

```{r, eval=TRUE, echo=TRUE}
#| label: fig-classification
#| fig-cap: "Barplot et Dendrogramme" 
#| fig-subcap:
#|   - "Barplot"
#|   - "Dendrogramme" 
#| layout-ncol: 2

ggplot(barplot_df, aes(x = index, y = height)) +
   labs(x = "Index",
       y = "Va") +
  geom_bar(stat = "identity", fill = "royalblue") +
   theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "#FFFFF6")) +
  theme_bw() 

ggplot(color_branches(arbre, k = 3), labels = FALSE)

```

A priori, notre √©chantillon se divise en trois groupes distincts. Par cons√©quent, nous pouvons effectuer une coupe de l'arbre de classification hi√©rarchique afin d'obtenir trois clusters. Apr√®s le calcul des centres de gravit√©, nous appliquons la m√©thode des k-means en utilisant l'algorithme de MacQueen. Ces calculs nous permettent d'identifier trois clusters constitu√©s comme ci-dessous.

| Phon√®mes | Clust. 1 | Clust. 2 | Clust. 3 |
|----------|----------|----------|----------|
| aa       | 1.0      | **24.6** | 0.2      |
| ao       | 0.6      | **35.9** | 1.9      |
| dcl      | 0.4      | 1.5      | **97.6** |
| iy       | 9.5      | **37.6** | 0.4      |
| sh       | **88.5** | 0.3      | 0        |

: R√©partition des phon√®mes dans les diff√©rents clusters (en %) {#tbl-clust}

La @tbl-clust indique comment chaque phon√®me est r√©parti. Nous observons que le premier cluster est majoritairement compos√© du phon√®me *sh* avec 88,5% des observations. Le second, le plus important en termes d'effectif, est principalement constitu√© des phon√®mes *aa*, *ao* et *iy*. Enfin, le troisi√®me cluster se compose presque exclusivement du phon√®me *dcl* avec 97,6% des observations. Ainsi, le clustering effectu√© confirme les premi√®res observations faites dans la partie statistiques descriptives : nous identifions bien trois groupes distincts, dont trois phon√®mes partageant des caract√©ristiques tr√®s similaires entre eux et deux autres poss√©dant leurs propres sp√©cificit√©s. Pour v√©rifier si les associations entre les clusters et les phon√®mes sont significatives, nous pouvons utiliser le test du $\chi2$. En effectuant le test √† l'aide de la commande `chisq.test` sur le logiciel R, nous obtenons une p-value inf√©rieure √† 0,05. Par cons√©quent, nous pouvons conclure qu'il existe une association significative entre les phon√®mes et les clusters. En ce qui concerne l'interpr√©tation des clusters, nous pouvons faire certaines hypoth√®ses. Par exemple, le premier cluster pourrait √™tre associ√© √† des phon√®mes "chuchot√©s" ou prononc√©s avec une certaine r√©serve. Le deuxi√®me cluster pourrait correspondre √† des phon√®mes "vibrants" ou "nasalis√©s", qui pr√©sentent des caract√©ristiques acoustiques similaires en termes de fr√©quence. Le troisi√®me cluster pourrait √™tre associ√© √† des phon√®mes prononc√©s avec une certaine emphase ou une accentuation particuli√®re.

```{r, eval=TRUE, echo=FALSE, include=FALSE}
res.cutree <- cutree(data.hca, 3) # Coupe l'arbre de classification hi√©rarchique en 3 clusters.

centers <- aggregate(data.cr, by=list(res.cutree), FUN=mean) # Calcule les centres de gravit√© (moyennes) des 3 clusters obtenus √† partir de la classification hi√©rarchique.

centers <- centers[,-1] # Supprime la premi√®re colonne des centres, qui contient les identifiants de cluster (g).

data.kmeans <- kmeans(data.cr, centers=centers, algorithm="MacQueen") # Clustering k-means en utilisant les centres de gravit√© calcul√©s pr√©c√©demment comme centres initiaux, avec l'algorithme de MacQueen.

data.kmeans.alea <- kmeans(data.cr, centers=centers, nstart = 50, iter.max = 50, algorithm="MacQueen") # clustering k-means avec les centres initiaux, mais en effectuant 50 it√©rations maximales et en choisissant la meilleure solution parmi 50 essais al√©atoires.

data.tot <- cbind(as.data.frame(df_train), Clas = as.factor(data.kmeans$cluster))  # ajoute une colonne "Clas" √† l'ensemble de donn√©es original, contenant les r√©sultats du clustering k-means.
```

```{r,  eval=TRUE, echo=FALSE, include=FALSE}
#| label: tbl-clust
#| tbl-cap: "Iris Data"
par(mfrow = c(1,3))
kable(table(data.tot[,c(1,258)])) # Tableau crois√© des clusters et de la premi√®re variable (colonne 1) de l'ensemble de donn√©es.

```

```{r, eval=TRUE, echo=FALSE, include=FALSE}
chisq.test(table(data.tot[,c(1,258)])) # test du khi2 d'ind√©pendance pour d√©terminer s'il existe une association significative entre la premi√®re variable et les clusters.
```

```{r, echo=FALSE, eval=TRUE, include=FALSE}
#Code pour avoir les pourcentages dans le tableau 

# Recalcul du tableau de r√©partition des phon√®mes dans les diff√©rents clusters
tbl_clust <- table(data.tot[,c(1,258)])

# Calcul des pourcentages de chaque phon√®me dans chaque cluster
pourcentages <- round(prop.table(tbl_clust, margin = 2) * 100, 1)

# Ajout d'une colonne avec les pourcentages de chaque phon√®me dans chaque cluster
tbl_clust <- cbind(tbl_clust, pourcentages)

# Affichage du tableau mis √† jour
tbl_clust

```

# Discrimination

Le but de cette partie va √™tre de mener une analyse discriminante sur nos phon√®mes. Tr√®s simplement, l'analyse discriminante est une m√©thode statistique utilis√©e pour trouver les caract√©ristiques qui diff√©rencient le mieux des groupes d'observations. Ici, notre objectif va donc √™tre de trouver les fr√©quences acoustiques qui permettent de diff√©rencier au mieux les diff√©rents phon√®mes. Mieux diff√©rencier les phon√®mes peut nous permettre *in fine* d'am√©liorer nos connaissances dans le domaine de la reconnaissance vocale. Pour effectuer cette discrimination, nous utiliserons deux m√©thodes, l'analyse factorielle discriminante et la PLS DA.

## Analyse Factorielle discriminante

L'analyse factorielle discriminante (AFD) est une m√©thode statistique qui permet d'identifier les fr√©quences acoustiques discriminantes pour les diff√©rents phon√®mes. Pour mener √† bien cette technique, les donn√©es sont divis√©es en deux √©chantillons. Ensuite, le mod√®le est entra√Æn√© √† l'aide de la fonction `lda` du package `MASS`. Afin d'estimer la pr√©cision du mod√®le, il est possible de le tester sur l'√©chantillon test et d'obtenir une matrice de confusion (@tbl-AFD ). Cette matrice permet de visualiser la r√©partition des phon√®mes entre leurs classes initiales et les classes pr√©dites par le mod√®le. Les r√©sultats montrent que le mod√®le est assez pr√©cis, √† l'exception des phon√®mes *aa* et *ao* qui pr√©sentent un taux d'erreur d'environ 20%, tandis que tous les autres phon√®mes ont un taux d'erreur proche de 1%. Ces r√©sultats sont confirm√©s par la pr√©cision globale du mod√®le, qui s'√©l√®ve √† 93%.

| Classe Pr√©dite | aa  | ao  | dcl | iy  | sh  |
|----------------|-----|-----|-----|-----|-----|
| **aa**         | 106 | 30  | 0   | 0   | 0   |
| **ao**         | 33  | 186 | 0   | 0   | 0   |
| **dcl**        | 0   | 0   | 182 | 2   | 0   |
| **iy**         | 0   | 0   | 3   | 259 | 0   |
| **sh**         | 0   | 0   | 1   | 0   | 200 |

: Matrice de confusion de l'AFD {#tbl-AFD}

```{r, echo=FALSE, eval=FALSE}

### Pr√©paration des donn√©es
# S√©lection des variables x.1 √† x.256
X <- df_train[, 2:257]

# Variables de r√©ponse
y <- df_train[, 1]

# Division des donn√©es en ensembles d'apprentissage et de test
train_index <- sample(1:nrow(df_train), size = round(nrow(df_train) * 0.7), replace = FALSE)
train_set <- df_train[train_index, ]
test_set <- df_train[-train_index, ]

```

```{r, echo=FALSE, eval=FALSE}
# Entra√Ænement du mod√®le
model_lda <- lda(x = train_set[, 2:257], grouping = train_set[, 1])

# Pr√©diction des classes dans l'ensemble de test
lda_prediction <- predict(model_lda, newdata = test_set[, 2:257])

```

```{r, echo=FALSE, eval=FALSE}
### Mesures de performances
# Matrice de confusion
table(lda_prediction$class, test_set[, 1])

```

```{r, echo=FALSE, eval=FALSE}
# Pr√©cision globale
mean(lda_prediction$class == test_set[,1])

```

### Variables les plus discriminantes

A pr√©sent, nous proc√©dons √† l'identification des phon√®mes les plus discriminants. En obtenant les scores d'importance des variables, nous observons que les dix phon√®mes les plus discriminants se situent presque tous autour de la fr√©quence x20 (@tbl-10). Nous pouvons ainsi affirmer que les fr√©quences basses, c'est-√†-dire celles du d√©but du spectre, sont les plus importantes pour distinguer les diff√©rents groupes de phon√®mes dans notre jeu de donn√©es. Nous pouvons √©mettre l'hypoth√®se que les caract√©ristiques acoustiques des phon√®mes peuvent varier en fonction de l'articulation et de la position dans la parole. Les fr√©quences basses pourraient ainsi refl√©ter des aspects importants de l'articulation, tels que la mani√®re dont les cordes vocales vibrent ou la mani√®re dont les cavit√©s buccales et nasales modifient les sons produits. Ces fr√©quences basses pourraient donc fournir des informations cruciales pour diff√©rencier les phon√®mes.

| Variables | coef       | importance |
|-----------|------------|------------|
| x.17      | -0.1435770 | 0.0206144  |
| x.18      | -0.1326711 | 0.0176016  |
| x.19      | -0.1185520 | 0.0140546  |
| x.20      | -0.1125399 | 0.0126652  |
| x.12      | 0.1018741  | 0.0103783  |
| x.9       | 0.0883249  | 0.0078013  |
| x.16      | -0.0865254 | 0.0074866  |
| x.35      | -0.0821173 | 0.0067433  |
| x.10      | 0.0802089  | 0.0064335  |
| x.11      | 0.0750107  | 0.0056266  |

: Les 10 fr√©quences les plus discriminantes {#tbl-10}

Pour conclure avec cette m√©thode, nous avons tent√© d'utiliser la m√©thode LASSO (Least Absolute Shrinkage and Selection Operator) pour s√©lectionner les variables les plus pertinentes pour la classification. Malheureusement, nos r√©sultats ont indiqu√© que le processus de s√©lection de variables n'avait pas d'impact significatif sur la performance du mod√®le.

```{r, echo=FALSE, eval=FALSE}

# Obtention des coefficients du mod√®le
coef_lda <- coef(model_lda)


# Obtention des scores d'importance des variables
importance <- abs(model_lda$scaling)^2


# Cr√©ation d'un dataframe contenant les coefficients et leur importance relative
coef_df <- data.frame(variable = colnames(train_set[, 2:257]),
                      coef = coef_lda[,1],
                      importance = importance[,1])

# Tri du dataframe par importance d√©croissante
sorted_coef_df <- coef_df[order(-coef_df$importance),]

# Affichage des 10 premi√®res variables les plus discriminantes
kable(head(sorted_coef_df, 10))
```

```{r, echo=FALSE, eval=FALSE}
### AFD avec s√©lection de variables

X_train <- as.matrix(train_set[, 2:257])
y_train <- train_set[, 1]
X_test <- as.matrix(test_set[, 2:257])
y_test <- test_set[, 1]


# S√©lection de variables avec LASSO
lasso_model <- cv.glmnet(X_train, y_train, family = "multinomial", type.measure = "class", nfolds = 10)

# Variables s√©lectionn√©es
selected_vars_list <- predict(lasso_model, s = "lambda.min", type = "nonzero")
selected_vars_indices <- unlist(selected_vars_list)

# Cr√©ation de nouveaux ensembles d'apprentissage et de test avec les variables s√©lectionn√©es
X_train_selected <- X_train[, selected_vars_indices]
X_test_selected <- X_test[, selected_vars_indices]

# Entra√Ænement du mod√®le LDA avec les variables s√©lectionn√©es
model_lda_selected <- lda(x = X_train_selected, grouping = y_train)

# Pr√©diction des classes dans l'ensemble de test avec le mod√®le LDA ajust√©
lda_prediction_selected <- predict(model_lda_selected, newdata = X_test_selected)

# Matrice de confusion
table(lda_prediction_selected$class, y_test)

# Pr√©cision globale
mean(lda_prediction_selected$class == y_test)

```

## PLS-DA

La deuxi√®me m√©thode d'analyse supervis√©e que nous avons utilis√©e pour cette √©tude est la PLS-DA. Cette analyse est int√©ressante et vient compl√©ter l'AFD, car elle nous permet de prendre en compte la corr√©lation qui peut exister entre les diff√©rentes caract√©ristiques acoustiques de nos phon√®mes. De plus, la PLS-DA permet de pr√©dire la classe d'un nouvel individu en fonction de ses caract√©ristiques acoustiques. Dans le cas de l'analyse des phon√®mes, cela peut √™tre utile pour identifier la classe d'un phon√®me inconnu √† partir de ses caract√©ristiques acoustiques. Pour r√©aliser notre PLS-DA, nous avons utilis√© uniquement le package `Mix0mics` de R. Comme pour l'AFD, nous avons commenc√© par d√©finir deux √©chantillons, un d'apprentissage et un d'entra√Ænement. Ensuite, nous avons utilis√© la fonction `plsda` avec l'√©chantillon d'apprentissage pour estimer un premier mod√®le. Notons que ce mod√®le est effectu√© sur cinq composantes pour les cinq phon√®mes. √Ä la suite de ce premier mod√®le, nous avons obtenu un graphique relativement similaire √† ce qui avait pu √™tre fait dans notre partie d'analyse de donn√©es. Cependant, en utilisant la validation crois√©e, nous avons d√©termin√© un nombre optimal de trois composantes. La @fig-plsda3 nous donne une repr√©sentation graphique de la PLS-DA effectu√©e. Nous pouvons observer que mise √† part les phon√®mes *aa* et *ao*, les trois autres phon√®mes arrivent bien √† se d√©tacher et √† se regrouper entre eux par rapport √† la premi√®re PLS-DA effectu√©e sur cinq composantes.

```{r, echo=FALSE, eval=TRUE, include = FALSE}

# S√©paration des donn√©es en matrices X et Y
X_train <- as.matrix(df_train[,2:257])
Y_train <- as.factor(df_train[,1])

# R√©alisation de l'analyse PLS-DA
plsda_res5 <- plsda(X_train, Y_train, ncomp = 5)





list.keepX <- c(1:5)  
tune.splsda_1 <- tune.splsda(X_train, Y_train, ncomp = 3, validation = 'Mfold', folds = 5,
                             progressBar = FALSE, dist = 'mahalanobis.dist', measure = "overall",
                             test.keepX = list.keepX, nrepeat = 10, cpus = 2)

error <- tune.splsda_1$error.rate  # taux d'erruer 
tune.splsda_1$choice.ncomp

ncomp <- tune.splsda_1$choice.ncomp$ncomp # Nombre optimal de composantes
ncomp

# R√©alisation de l'analyse PLS-DA
plsda_res3 <- plsda(X_train, Y_train, ncomp = 3)

```

```{r, eval=TRUE, echo=TRUE, include=TRUE}
#| label: fig-plsda3
#| fig-cap: "Repr√©sentations graphiques des PLS-DA"
#| fig-subcap:
#|   - "5 composantes"
#|   - "3 composantes" 
#| layout-ncol: 2
# Visualisation des individus dans l'espace des trois premi√®res composantes principales
plotIndiv(plsda_res5, group = Y_train, legend.title = "Phon√®me", ellipse = TRUE, legend = TRUE,
          title = "PLS-DA sur cinq composantes")
plotIndiv(plsda_res3, comp = c(1,3), group = Y_train, legend.title = "Phon√®me", ellipse = TRUE, legend = TRUE,
          title =" PLS-DA sur trois composantes")

```

### Mesures de performances

Afin d'√©valuer la performance du mod√®le, nous avons proc√©d√© √† une pr√©diction sur l'√©chantillon test. La mesure utilis√©e pour cette pr√©diction est la distance de Mahalanobis, qui permet d'√©valuer la similarit√© entre deux observations en prenant en compte leur corr√©lation. Dans le cadre de notre √©tude, cette distance indique un taux de classification correcte de 0,7197, soit 71,97% d'observations correctement class√©es en fonction de leur groupe d'appartenance. Comme pour l'analyse factorielle discriminante, une matrice de confusion a √©t√© construite √† partir de l'√©chantillon test. Cette matrice r√©v√®le un taux d'erreur de 22%, ce qui indique une pr√©cision moindre du mod√®le. Ce taux d'erreur est d√ª √† la difficult√© pour le mod√®le √† distinguer les diff√©rences entre les deux phon√®mes les plus proches, √† savoir *aa* et *ao.*

```{r, echo=FALSE, eval=TRUE, include=FALSE}
# Pr√©diction des classes des individus de l'√©chantillon de test
X_test <- as.matrix(df_test[,2:257])
Y_test <- df_test[, 1]
Y_test_pred <- predict(plsda_res3, newdata = X_test)$class

# Calcul du taux de bonne classification
mean(Y_test_pred[["mahalanobis.dist"]] == df_test[,1])

test.predict <- predict(plsda_res3, X_test, dist = "max.dist")
Prediction <- test.predict$class$max.dist[, 3]
confusion.mat <- get.confusion_matrix(truth = Y_test, predicted = Prediction)
confusion.mat
get.BER(confusion.mat)

```

### Contribution aux composantes

Enfin, pour compl√©ter l'analyse, nous avons d√©cid√© de projeter les fr√©quences acoustiques ayant le plus d'importances dans la formation de nos trois composantes (@fig-comp). Les fr√©quences acoustiques les plus discriminantes pour la composante 1 sont celles qui se trouvaient √† droite du spectre acoustique et qui correspondaient au phon√®me *sh.* Les fr√©quences les plus discriminantes pour les composantes 2 et 3 sont les fr√©quences les plus basses, correspondant respectivement aux phon√®mes *aa*, *ao* et *iy.* Cependant, aucune des variables correspondantes n'a contribu√© n√©gativement √† la composante 2, alors que le phon√®me *iy* a contribu√© positivement √† la composante 3. Ainsi, il semble que les fr√©quences basses soient importantes pour la discrimination des phon√®mes, en particulier pour les phon√®mes *aa*, *ao* et *iy.* En revanche, les fr√©quences les plus √©lev√©es du spectre acoustique semblent √™tre importantes pour la discrimination du phon√®me *sh.* Ces r√©sultats sont coh√©rents avec la litt√©rature sur la perception des phon√®mes, qui indique que les fr√©quences basses peuvent √™tre importantes pour la reconnaissance des phon√®mes, en particulier pour les voyelles.

```{r, eval=TRUE, echo=TRUE, include=TRUE}
#| label: fig-comp
#| fig-cap: "Contributions des individus aux trois composantes"
#| fig-subcap:
#|   - "Composante 1"
#|   - "Composante 2" 
#|   - "Composante 3"
#| layout-ncol: 3
# Visualisation des individus dans l'espace des trois premi√®res composantes principales
plotLoadings(plsda_res3, comp = 1, method = 'median', contrib = "max", title = "Composante 1")
plotLoadings(plsda_res3, comp = 2, method = 'median', contrib = "max", title = "Composante 2")
plotLoadings(plsda_res3, comp = 3, method = 'median', contrib = "max", title = "Composante 3")
```

# Conclusion

En utilisant des m√©thodes de statistiques et d'analyse de donn√©es, l'objectif de cette √©tude √©tait de mieux comprendre les liens entre les phon√®mes et les fr√©quences sonores. Dans la premi√®re partie, une analyse de statistique descriptive a √©t√© r√©alis√©e pour distinguer trois groupes de phon√®mes. √Ä l'aide du graphique des individus et du periodogramme, des similitudes ont √©t√© observ√©es entre les phon√®mes *aa*, *ao* et *iy*, ainsi qu'une opposition entre les phon√®mes *dcl* et *sh*. Ces observations ont √©t√© confirm√©es par notre classification qui a permis de d√©gager trois clusters distincts. En accord avec l'analyse pr√©liminaire, le cluster 1 √©tait majoritairement compos√© du phon√®me *sh*, le cluster 2 √©tait majoritairement compos√© des phon√®mes *aa*, *ao* et *sh*, et enfin, le cluster 3 √©tait compos√© en grande partie du phon√®me *dcl*.

Ensuite, une analyse discriminante a √©t√© r√©alis√©e pour identifier les fr√©quences sonores qui permettaient de discriminer au mieux les diff√©rents phon√®mes. L'analyse discriminante factorielle a montr√© que ce sont les fr√©quences les plus basses qui semblaient discriminer au mieux les diff√©rents phon√®mes. Cette observation est en accord avec l'analyse du periodogramme qui montrait que le niveau des fr√©quences √©tait en moyenne plus √©lev√© au d√©but du spectre sonore. Bien que ces observations ne permettent pas de tirer des conclusions certaines, il est possible que ces r√©sultats soient dus au fait que tous les phon√®mes √©tudi√©s sont des voyelles.

Enfin, pour compl√©ter notre analyse discriminante, une analyse PLS-DA a √©t√© effectu√©e. Les r√©sultats de cette PLS-DA ont confirm√© que les fr√©quences les plus basses pouvaient √™tre un facteur discriminant pour l'identification des phon√®mes, en particulier pour les phon√®mes les plus similaires, tels que *aa*, *ao* et *iy*. Cependant, les performances de la PLS-DA se sont av√©r√©es moins robustes que celles de l'AFD. Dans le cadre de cet √©chantillon, il est donc possible que l'AFD soit suffisante pour obtenir une bonne discrimination.

# Discussion

Si dans cette √©tude, nous avons identifi√© les fr√©quences basses comme √©tant un √©l√©ment cl√© pour discriminer les phon√®mes, il est utile de pr√©ciser que ces caract√©ristiques acoustiques ne sont pas les seules √† pouvoir les discriminer. D'autres caract√©ristiques telles que la dur√©e du phon√®me ou les transitions de fr√©quences entre les phon√®mes peuvent √©galement jouer un r√¥le important dans la reconnaissance vocale. Dans cette √©tude, nous avons d√ª faire avec les donn√©es qui nous √©taient fournis, ainsi les r√©sultats pourraient s'av√©rer diff√©rents avec un autre √©chantillon de phon√®mes. De plus, il faut tenir compte du fait que ces r√©sultats ne sont pas forc√©ment g√©n√©ralisable √† d'autres langues et populations.

[PDF](var_latentes.pdf)
