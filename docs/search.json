[
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "üìß",
    "section": "",
    "text": "For any inquiries, collaboration opportunities, or just to say hi, you can reach me at :\ngabriel.ammour@gmail.com"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Sierpi≈Ñski triangle",
    "section": "",
    "text": "Heron‚Äôs formula is a formula for finding the area of a triangle when you know the lengths of its three sides. It is named after the ancient Greek mathematician, Hero of Alexandria, who first described it.\n\\[A = \\sqrt{s(s-a)(s-b)(s-c)}\\]\nwhere \\(a\\), \\(b\\), and \\(c\\) are the lengths of the sides of the triangle, \\(s\\) is the semiperimeter of the triangle, which is defined as \\(s = \\frac{1}{2}(a + b + c)\\), and \\(A\\) is the area of the triangle. The reason Heron‚Äôs formula works is that it is based on the concept of the ‚ÄúHeronian triangle,‚Äùwhich is a triangle with integer sides and integer area. Heron‚Äôs formula gives the exact area of a Heronian triangle, and it turns out that every triangle can be split into two Heronian triangles. So, by using Heron‚Äôs formula to find the area of each of these two triangles and adding the results, you get the area of the original triangle.\n\n\nThe package must be install through my personal GitHub account. Install the library remotes and then :\n\nremotes::install_github(\"gabammour/heron\")\nlibrary(heron)\n\nFor more information on this package, use :\n\n?heron"
  },
  {
    "objectID": "posts/post-with-code/index.html#how-can-i-install-it",
    "href": "posts/post-with-code/index.html#how-can-i-install-it",
    "title": "Heron‚Äôs library",
    "section": "How can I install it ?",
    "text": "How can I install it ?\nThe package must be install through my personal GitHub account. Install the library remotes and then :\n\nremotes::install_github(\"gabammour/heron\")\nlibrary(heron)\n\nFor more information on this package, use :\n\n?heron"
  },
  {
    "objectID": "posts/post-with-code/index.html#triangle",
    "href": "posts/post-with-code/index.html#triangle",
    "title": "Heron‚Äôs library",
    "section": "Triangle",
    "text": "Triangle\n\n\n\n\nFirst iteration\n\n\n\n\n\n[1] \"The triangle area is : 0.19\"\n\n\n\n\nSecond iteration\n\n\n\n\n\n[1] \"The triangle area is :  0.14\"\n\n\n\n\nThird iteration\n\n\n\n\n\n[1] \"The triangle area is :  0.11\"\n\n\n\n\nFourth iteration\n\n\n\n\n\n[1] \"The triangle area is :  0.0791\"\n\n\nOn s‚Äôapper√ßoit bien de la d√©croissance des aires."
  },
  {
    "objectID": "posts/EPU/index.html",
    "href": "posts/EPU/index.html",
    "title": "Using annotate and geom_segment to valuate you times series",
    "section": "",
    "text": "The Economic Policy Uncertainty Index (EPU)1\nThe EPU index was first introduced by Scott R. Baker, Nick Bloom, and Stephen J. Davis in a seminal paper published in 2012. The index is based on the frequency of newspaper articles that mention policy-related economic uncertainty. The authors argue that this measurement is an accurate proxy for economic policy uncertainty, as media coverage of policy-related uncertainty reflects the opinions and views of experts, market participants, and the general public.\n\n\nPlotting of the EPU Index\nThe R code provided in this article uses the ggplot2 library to visualize the EPU index over time. The code starts by defining the data source (base) and creating a plot object with the x-axis representing the date and the y-axis representing the EPU index. The plot is then decorated with various elements to enhance its readability and aesthetic appeal.\nThe scale_x_date function is used to set the date format and to break the x-axis into intervals of 5 years. The scale_y_continuous function sets the limits of the y-axis to a range of 0 to 320. The theme_light function sets the plot‚Äôs overall theme to a light color palette, while the theme function sets the color, size, and type of the axis lines.\nThe annotate function is used to add text annotations to the plot, highlighting important economic events such as the subprime crisis, the 9/11 attacks, and the Covid-19 pandemic. The geom_segment function is used to add arrows to the plot, showing the direction and magnitude of the changes in the EPU index. The theme function is then used to set the legend position, justification, direction, and to add a caption to the plot.\n\n\nConclusion\nThe R code provided in this article is a simple yet effective way of visualizing the EPU index and its relationship with significant economic events. The plot highlights the impact of various events on the uncertainty index, making it a useful tool for economists, policymakers, and market participants to gain insights into the economic policy environment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nplot_EPU <- ggplot(base, aes(x = Date)) +\n  geom_line(aes(y = EPU, color = \"EPU\")) +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"5 years\") +\n  scale_y_continuous(limits = c(0,320)) +\n  theme_light() +\n  theme(axis.line = element_line(colour = \"black\",size = 0.2, linetype = \"solid\")) +\n  annotate(\"text\", x = as.Date(\"2020-03-01\", format = \"%Y-%m-%d\"), y = 320, label = \"Covid-19\", color = \"black\", angle=0,  size = 2) +\n  annotate(\"text\", x = as.Date(\"2006-12-01\", format = \"%Y-%m-%d\"), y = 190, label = \"Subprime\", color = \"black\", angle=0, size = 2) +\n  annotate(\"text\", x = as.Date(\"1986-10-19\", format = \"%Y-%m-%d\"), y = 185, label = \"Black Monday\", color = \"black\", angle=0, size = 2) +\n  annotate(\"text\", x = as.Date(\"2001-09-11\", format = \"%Y-%m-%d\"), y = 200, label = \"9/11\", color = \"black\", angle=0, size = 2) +\n  annotate(\"text\", x = as.Date(\"2011-03-01\", format = \"%Y-%m-%d\"), y = 260, label = \"Euro debt crisis\", color = \"black\", angle=0, size = 2) +\n  annotate(\"text\", x = as.Date(\"1990-10-01\", format = \"%Y-%m-%d\"), y = 185, label = \"Gulf war I\", color = \"black\", angle=0, size = 2) +\n  geom_segment(aes(x = as.Date(\"2007-01-01\", format = \"%Y-%m-%d\"), y = 180, xend = as.Date(\"2008-01-01\", format = \"%Y-%m-%d\") , yend=150), arrow = arrow(length = unit(.12, \"cm\"),type = \"closed\")) +\n  geom_segment(aes(x = as.Date(\"1987-01-19\", format = \"%Y-%m-%d\"), y = 180, xend = as.Date(\"1987-10-19\", format = \"%Y-%m-%d\"), yend = 165), arrow = arrow(length = unit(.12, \"cm\"),type = \"closed\")) +\n  theme(legend.position = \"bottom\", \n        legend.justification = \"left\",\n        legend.direction = \"horizontal\") +\n  xlab(\"Date\") + ylab(\"Economic policy Uncertainty Index\") +\n  labs(caption = \"Source: Baker, Scott R., Bloom, Nick and Davis, Stephen J., Economic Policy Uncertainty Index for United States\", color = \"Legend : \") +\n  theme(text = element_text(family = \"Helvetica\"))\n\nplot_EPU\n\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nMeasuring Economic Policy Uncertainty.‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/meat_consumption/index.html",
    "href": "posts/meat_consumption/index.html",
    "title": "Studying meat consumption among college students",
    "section": "",
    "text": "Methods\nTo achieve this, we conducted an online survey to evaluate the students‚Äô positions on these three causes. The results of the survey allowed us to segment the population into four types of consumers: inactive, occasional, regular, and dependent. Using multiple component analysis and clustering techniques, we were then able to determine three distinct clusters: the committed, the aware, and the skeptical. We used the ordinary least squares method to quantify and measure the magnitude of these relationships, though we caution that our results may be affected by an endogeneity problem. Despite these limitations, our findings suggest that food and health behaviors, as well as environmental concerns, have a significant impact on meat consumption among students at the University of Nantes.\n\n\nResults\nOur findings indicated that the majority of the student population was aware of the negative impacts of the meat industry on the environment, health, and animal welfare. However, we observed a clear relationship between the students‚Äô cluster membership and their meat consumption patterns. Students who were skeptical about environmental, health, and animal considerations tended to be regular or dependent meat consumers, while those who were committed to food and health behaviors and environmental concerns consumed on average almost half as much meat as the aware students.\n\n\nConclusion\nIn conclusion, our report highlights the need for public policies to be more specific in addressing the hazards of meat consumption, particularly processed meat, on the health of all citizens. Given that the student population seems to be relatively well-informed about animal and environmental issues, there may be an opportunity to better educate them about the health effects of meat consumption and encourage more sustainable dietary habits. As the world faces the challenges of a rapidly growing population and limited resources, reducing our dependence on meat will likely be necessary for a sustainable and healthy future.\nFull text pdf here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "School projects\n\n\n\n\nüîâ\n\n\n\n\n\n\nApr 6, 2023\n\n\nGabriel Ammour, Th√©o Bouedo\n\n\n21 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nSchool projects\n\n\n\n\nüêô\n\n\n\n\n\n\nMar 12, 2023\n\n\nGabriel Ammour, Th√©o Bouedo\n\n\n11 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nSchool projects\n\n\n\n\nüìê\n\n\n\n\n\n\nFeb 21, 2023\n\n\nGabriel Ammour\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nüìà\n\n\n\n\n\n\nFeb 4, 2023\n\n\nGabriel Ammour\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nSchool projects\n\n\n\n\nü•©\n\n\n\n\n\n\nFeb 4, 2023\n\n\nGabriel Ammour, Th√©o Bouedo, Noa Le Roux\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nSchool projects\n\n\n\n\nüòÉ\n\n\n\n\n\n\nNov 1, 2022\n\n\nGabriel Ammour, Noa Le Roux\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "üôãüèΩ",
    "section": "",
    "text": "In my blog, I aim to provide an insightful and educational platform for anyone who is interested in my journey as a Master‚Äôs student in Applied Econometrics. I will be sharing regular updates on my studies, as well as tips and advice on topics such as data science, academic writing, and more. Whether you‚Äôre a fellow student, a professional in a related field, or simply someone with a passion for learning, I hope that my blog will be a valuable resource for you. So, feel free to check it out and join me on this journey.\nHave a great day !\n\nüòá\n\n\n\n\nFootnotes\n\n\nPhoto taken by Tom David-Kemp, 2020.‚Ü©Ô∏é"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "üéì",
    "section": "",
    "text": "2022-2024 Master in Applied Econometrics, Nantes University üá≤üá´\n2021-2022 Exchange program, Sherbrooke University üá®üá¶\n2019-2022 Bachelor degree in Economics, Nantes University üá≤üá´"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "üéì",
    "section": "Skills",
    "text": "Skills\n```{r}\ngabriel %>% intermediate user\n# Favorite libraries \nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n```\n```{python}\nimport gabriel as beginner\n```"
  },
  {
    "objectID": "cv.html#languages",
    "href": "cv.html#languages",
    "title": "üéì",
    "section": "Languages",
    "text": "Languages\nüá≤üá´ Bilingual (Native thong)\nüá∫üá≤ C1 TOEIC, 980/990\nüá™üá∏ Notion\n‚Ä¶ Also, fluent in \\(\\LaTeX\\)\nFull CV"
  },
  {
    "objectID": "posts/post-with-code/index.html#sierpi≈Ñski-triangle",
    "href": "posts/post-with-code/index.html#sierpi≈Ñski-triangle",
    "title": "Sierpi≈Ñski triangle",
    "section": "Sierpi≈Ñski triangle",
    "text": "Sierpi≈Ñski triangle\nThe Sierpi≈Ñski triangle is a fractal that is formed through an iterative process known as the chaos game. Starting with a single equilateral triangle, each subsequent iteration involves selecting a random vertex of the triangle and placing a new triangle with sides that are half the length of the original triangle. The new triangle is positioned such that its base coincides with the side opposite the selected vertex of the previous triangle.\n\n\n\n\nFirst iteration\n\n\n\n\n\n[1] \"The triangle area is 0.19\"\n\n\n\n\nSecond iteration\n\n\n\n\n\n[1] \"The triangle area is 0.14\"\n\n\n\n\nThird iteration\n\n\n\n\n\n[1] \"The triangle area is 0.11\"\n\n\n\n\nFourth iteration\n\n\n\n\n\n[1] \"The triangle area is 0.0791\""
  },
  {
    "objectID": "posts/GitHub-Essay/Index.html",
    "href": "posts/GitHub-Essay/Index.html",
    "title": "Platform Essay : GitHub",
    "section": "",
    "text": "This composition was produced with the intent of fulfilling the requirements of the course Economie numerique, which was conducted by Raphael Suire within the Master ECAP program at IAE Nantes. For ease of access, the PDF version of this composition can be found here."
  },
  {
    "objectID": "posts/GitHub-Essay/Index.html#value-proposition",
    "href": "posts/GitHub-Essay/Index.html#value-proposition",
    "title": "Platform Essay : GitHub",
    "section": "Value proposition",
    "text": "Value proposition\nGitHub‚Äôs value proposition is based on four primary pillars. The foremost and most critical of these pillars is collaboration. Through the use of powerful tools such as repositories, GitHub provides an environment in which multiple developers can work simultaneously on the same codebase. Simply put, a repository is a virtual space where individuals can store and manage their code, similar to a folder on a local computer. However, in this case, the repository is located on GitHub servers, which are hosted in the cloud. If a repository is public, any user can access and modify its contents, fostering a sense of collaboration and teamwork.\nThe second pillar of GitHub is version control. The platform‚Äôs version control system, Git, enables developers to track changes to code over time, facilitating the identification and correction of bugs and errors.\nThe third pillar is the community. GitHub boasts a vast and active community of developers who contribute to open-source projects, share code, and provide support to one another. This sense of community is a crucial aspect of GitHub‚Äôs value proposition, as it promotes knowledge-sharing and facilitates the exchange of ideas.\nFinally, the fourth pillar of GitHub is integration. The platform can be seamlessly integrated with a broad range of third-party tools and services, creating a central hub for managing the entire software development workflow. This feature streamlines the development process, making it more efficient and effective."
  },
  {
    "objectID": "posts/GitHub-Essay/Index.html#revenue-model",
    "href": "posts/GitHub-Essay/Index.html#revenue-model",
    "title": "Platform Essay : GitHub",
    "section": "Revenue model",
    "text": "Revenue model\nAs with many pure players, GitHub provides both free and paid services, operating on a freemium model. This approach is a common business strategy employed by software companies and social media platforms, as it enables them to garner a large user base before monetizing their offerings. Specifically, GitHub‚Äôs platform offers a complimentary version that permits users to create an unlimited number of public repositories and collaborate with other developers on open-source projects. However, this free service is subject to limitations in storage capacity.\nThe second offering, the GitHub Pro version, works as an extension of the free iteration, increasing the user experience by expanding storage capacity and introducing features such as GitHub Support via email, GitHub Pages, and Protected branches. Although the initial two products are oriented towards single users, GitHub also provides the same two versions for teams and organizations. The team version is analogous to the pro version, but it enables teams to access private repositories and expand their membership. Meanwhile, the organization version mirrors the free version but caters to organizations. We may also mention that GitHub offers a student developer pack that provides free access to GitHub Pro for students.\nLastly, GitHub‚Äôs ultimate offering, GitHub Enterprise, is the most expensive and primarily targets large companies. It comes with a host of features, such as SAML single sign-on, advanced security measures, and GitHub Enterprise Support.\nFurthermore, GitHub provides several paid services, including GitHub Actions, GitHub Packages, and GitHub Marketplace. GitHub Actions empowers developers to automate their software development workflows, streamlining the process and saving time. Meanwhile, GitHub Packages is a service that enables developers to store and share code packages with other developers, enhancing collaboration and productivity. Finally, GitHub Marketplace offers a platform that enables developers to explore and install third-party tools and services that integrate with GitHub, broadening the scope and functionality of the platform. The last example of these additional services is GitHub Copilot, an AI pair programmer that helps developers write code faster by providing autocomplete suggestions."
  },
  {
    "objectID": "posts/ACP/index.html",
    "href": "posts/ACP/index.html",
    "title": "Les d√©terminants du bonheur : Une analyse en composantes principles",
    "section": "",
    "text": "Un tr√®s bon r√©sum√© de notre travail a d√©j√† √©t√© fais par Noa ici. Pour le pdf complet, cliquer ici."
  },
  {
    "objectID": "posts/PHONEMES/index.html#analyse-factorielle-discriminante",
    "href": "posts/PHONEMES/index.html#analyse-factorielle-discriminante",
    "title": "Une analyse du lien entre phon√®mes et fr√©quences sonores",
    "section": "Analyse Factorielle discriminante",
    "text": "Analyse Factorielle discriminante\nL‚Äôanalyse factorielle discriminante (AFD) est une m√©thode statistique qui permet d‚Äôidentifier les fr√©quences acoustiques discriminantes pour les diff√©rents phon√®mes. Pour mener √† bien cette technique, les donn√©es sont divis√©es en deux √©chantillons. Ensuite, le mod√®le est entra√Æn√© √† l‚Äôaide de la fonction lda du package MASS. Afin d‚Äôestimer la pr√©cision du mod√®le, il est possible de le tester sur l‚Äô√©chantillon test et d‚Äôobtenir une matrice de confusion (Table¬†2 ). Cette matrice permet de visualiser la r√©partition des phon√®mes entre leurs classes initiales et les classes pr√©dites par le mod√®le. Les r√©sultats montrent que le mod√®le est assez pr√©cis, √† l‚Äôexception des phon√®mes aa et ao qui pr√©sentent un taux d‚Äôerreur d‚Äôenviron 20%, tandis que tous les autres phon√®mes ont un taux d‚Äôerreur proche de 1%. Ces r√©sultats sont confirm√©s par la pr√©cision globale du mod√®le, qui s‚Äô√©l√®ve √† 93%.\n\n\nTable 2: Matrice de confusion de l‚ÄôAFD\n\n\nClasse Pr√©dite\naa\nao\ndcl\niy\nsh\n\n\n\n\naa\n106\n30\n0\n0\n0\n\n\nao\n33\n186\n0\n0\n0\n\n\ndcl\n0\n0\n182\n2\n0\n\n\niy\n0\n0\n3\n259\n0\n\n\nsh\n0\n0\n1\n0\n200\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariables les plus discriminantes\nA pr√©sent, nous proc√©dons √† l‚Äôidentification des phon√®mes les plus discriminants. En obtenant les scores d‚Äôimportance des variables, nous observons que les dix phon√®mes les plus discriminants se situent presque tous autour de la fr√©quence x20 (Table¬†3). Nous pouvons ainsi affirmer que les fr√©quences basses, c‚Äôest-√†-dire celles du d√©but du spectre, sont les plus importantes pour distinguer les diff√©rents groupes de phon√®mes dans notre jeu de donn√©es. Nous pouvons √©mettre l‚Äôhypoth√®se que les caract√©ristiques acoustiques des phon√®mes peuvent varier en fonction de l‚Äôarticulation et de la position dans la parole. Les fr√©quences basses pourraient ainsi refl√©ter des aspects importants de l‚Äôarticulation, tels que la mani√®re dont les cordes vocales vibrent ou la mani√®re dont les cavit√©s buccales et nasales modifient les sons produits. Ces fr√©quences basses pourraient donc fournir des informations cruciales pour diff√©rencier les phon√®mes.\n\n\nTable 3: Les 10 fr√©quences les plus discriminantes\n\n\nVariables\ncoef\nimportance\n\n\n\n\nx.17\n-0.1435770\n0.0206144\n\n\nx.18\n-0.1326711\n0.0176016\n\n\nx.19\n-0.1185520\n0.0140546\n\n\nx.20\n-0.1125399\n0.0126652\n\n\nx.12\n0.1018741\n0.0103783\n\n\nx.9\n0.0883249\n0.0078013\n\n\nx.16\n-0.0865254\n0.0074866\n\n\nx.35\n-0.0821173\n0.0067433\n\n\nx.10\n0.0802089\n0.0064335\n\n\nx.11\n0.0750107\n0.0056266\n\n\n\n\nPour conclure avec cette m√©thode, nous avons tent√© d‚Äôutiliser la m√©thode LASSO (Least Absolute Shrinkage and Selection Operator) pour s√©lectionner les variables les plus pertinentes pour la classification. Malheureusement, nos r√©sultats ont indiqu√© que le processus de s√©lection de variables n‚Äôavait pas d‚Äôimpact significatif sur la performance du mod√®le."
  },
  {
    "objectID": "posts/PHONEMES/index.html#pls-da",
    "href": "posts/PHONEMES/index.html#pls-da",
    "title": "Une analyse du lien entre phon√®mes et fr√©quences sonores",
    "section": "PLS-DA",
    "text": "PLS-DA\nLa deuxi√®me m√©thode d‚Äôanalyse supervis√©e que nous avons utilis√©e pour cette √©tude est la PLS-DA. Cette analyse est int√©ressante et vient compl√©ter l‚ÄôAFD, car elle nous permet de prendre en compte la corr√©lation qui peut exister entre les diff√©rentes caract√©ristiques acoustiques de nos phon√®mes. De plus, la PLS-DA permet de pr√©dire la classe d‚Äôun nouvel individu en fonction de ses caract√©ristiques acoustiques. Dans le cas de l‚Äôanalyse des phon√®mes, cela peut √™tre utile pour identifier la classe d‚Äôun phon√®me inconnu √† partir de ses caract√©ristiques acoustiques. Pour r√©aliser notre PLS-DA, nous avons utilis√© uniquement le package Mix0mics de R. Comme pour l‚ÄôAFD, nous avons commenc√© par d√©finir deux √©chantillons, un d‚Äôapprentissage et un d‚Äôentra√Ænement. Ensuite, nous avons utilis√© la fonction plsda avec l‚Äô√©chantillon d‚Äôapprentissage pour estimer un premier mod√®le. Notons que ce mod√®le est effectu√© sur cinq composantes pour les cinq phon√®mes. √Ä la suite de ce premier mod√®le, nous avons obtenu un graphique relativement similaire √† ce qui avait pu √™tre fait dans notre partie d‚Äôanalyse de donn√©es. Cependant, en utilisant la validation crois√©e, nous avons d√©termin√© un nombre optimal de trois composantes. La Figure¬†4 nous donne une repr√©sentation graphique de la PLS-DA effectu√©e. Nous pouvons observer que mise √† part les phon√®mes aa et ao, les trois autres phon√®mes arrivent bien √† se d√©tacher et √† se regrouper entre eux par rapport √† la premi√®re PLS-DA effectu√©e sur cinq composantes.\n\n\nCode\n# Visualisation des individus dans l'espace des trois premi√®res composantes principales\nplotIndiv(plsda_res5, group = Y_train, legend.title = \"Phon√®me\", ellipse = TRUE, legend = TRUE,\n          title = \"PLS-DA sur cinq composantes\")\nplotIndiv(plsda_res3, comp = c(1,3), group = Y_train, legend.title = \"Phon√®me\", ellipse = TRUE, legend = TRUE,\n          title =\" PLS-DA sur trois composantes\")\n\n\n\n\n\n\n\n\n(a) 5 composantes\n\n\n\n\n\n\n\n(b) 3 composantes\n\n\n\n\nFigure 4: Repr√©sentations graphiques des PLS-DA\n\n\n\n\nMesures de performances\nAfin d‚Äô√©valuer la performance du mod√®le, nous avons proc√©d√© √† une pr√©diction sur l‚Äô√©chantillon test. La mesure utilis√©e pour cette pr√©diction est la distance de Mahalanobis, qui permet d‚Äô√©valuer la similarit√© entre deux observations en prenant en compte leur corr√©lation. Dans le cadre de notre √©tude, cette distance indique un taux de classification correcte de 0,7197, soit 71,97% d‚Äôobservations correctement class√©es en fonction de leur groupe d‚Äôappartenance. Comme pour l‚Äôanalyse factorielle discriminante, une matrice de confusion a √©t√© construite √† partir de l‚Äô√©chantillon test. Cette matrice r√©v√®le un taux d‚Äôerreur de 22%, ce qui indique une pr√©cision moindre du mod√®le. Ce taux d‚Äôerreur est d√ª √† la difficult√© pour le mod√®le √† distinguer les diff√©rences entre les deux phon√®mes les plus proches, √† savoir aa et ao.\n\n\nContribution aux composantes\nEnfin, pour compl√©ter l‚Äôanalyse, nous avons d√©cid√© de projeter les fr√©quences acoustiques ayant le plus d‚Äôimportances dans la formation de nos trois composantes (Figure¬†5). Les fr√©quences acoustiques les plus discriminantes pour la composante 1 sont celles qui se trouvaient √† droite du spectre acoustique et qui correspondaient au phon√®me sh. Les fr√©quences les plus discriminantes pour les composantes 2 et 3 sont les fr√©quences les plus basses, correspondant respectivement aux phon√®mes aa, ao et iy. Cependant, aucune des variables correspondantes n‚Äôa contribu√© n√©gativement √† la composante 2, alors que le phon√®me iy a contribu√© positivement √† la composante 3. Ainsi, il semble que les fr√©quences basses soient importantes pour la discrimination des phon√®mes, en particulier pour les phon√®mes aa, ao et iy. En revanche, les fr√©quences les plus √©lev√©es du spectre acoustique semblent √™tre importantes pour la discrimination du phon√®me sh. Ces r√©sultats sont coh√©rents avec la litt√©rature sur la perception des phon√®mes, qui indique que les fr√©quences basses peuvent √™tre importantes pour la reconnaissance des phon√®mes, en particulier pour les voyelles.\n\n\nCode\n# Visualisation des individus dans l'espace des trois premi√®res composantes principales\nplotLoadings(plsda_res3, comp = 1, method = 'median', contrib = \"max\", title = \"Composante 1\")\nplotLoadings(plsda_res3, comp = 2, method = 'median', contrib = \"max\", title = \"Composante 2\")\nplotLoadings(plsda_res3, comp = 3, method = 'median', contrib = \"max\", title = \"Composante 3\")\n\n\n\n\n\n\n\n\n(a) Composante 1\n\n\n\n\n\n\n\n(b) Composante 2\n\n\n\n\n\n\n\n(c) Composante 3\n\n\n\n\nFigure 5: Contributions des individus aux trois composantes"
  }
]